#!/usr/bin/env python3
"""
å¿«é€Ÿè¿è¡Œå¥å­åˆ†æè„šæœ¬
ä¿®æ”¹è¾“å…¥æ–‡ä»¶è·¯å¾„åè¿è¡Œ: python run_sentence_analysis.py
"""

import asyncio
import logging
from sentence_analysis import SentenceAnalyzer
from pathlib import Path

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def main():
    # ========== é…ç½®åŒºåŸŸ ==========
    
    # ğŸ“ è¾“å…¥æ–‡ä»¶é…ç½®
    input_file = "data/processed/å¢ƒå¤–æ±‡æ€»_20250609_cleaned.csv"  # é¢„å¤„ç†ç»“æœæ–‡ä»¶
    
    # ğŸ“ è¾“å‡ºæ–‡ä»¶é…ç½®
    output_sentences = "data/processed/å¢ƒå¤–æ±‡æ€»_20250609_sentences.csv"      # å¥å­è¡¨
    output_summary = "data/processed/å¢ƒå¤–æ±‡æ€»_20250609_sentence_report.md"   # åˆ†ææŠ¥å‘Š
    output_samples = "data/processed/å¢ƒå¤–æ±‡æ€»_20250609_sentence_samples.csv" # å¥å­æ ·æœ¬
    
    # ğŸ¯ åˆ†æé…ç½®
    sample_size = 50  # æ ·æœ¬æ•°é‡
    
    # ========== æ‰§è¡Œåˆ†æ ==========
    
    print("ğŸš€ å¼€å§‹å¥å­åˆ‡åˆ†ç»“æœåˆ†æ...")
    print(f"ğŸ“„ è¾“å…¥æ–‡ä»¶: {input_file}")
    print("=" * 50)
    
    if not Path(input_file).exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        print("è¯·å…ˆè¿è¡Œé¢„å¤„ç†è„šæœ¬ç”Ÿæˆç»“æœæ–‡ä»¶")
        return
    
    try:
        # åˆ›å»ºåˆ†æå™¨
        analyzer = SentenceAnalyzer(input_file)
        
        # åŠ è½½æ•°æ®
        df = analyzer.load_data()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¥å­åˆ‡åˆ†ç»“æœ
        if 'sentences_detail' not in df.columns:
            print("âŒ è¾“å…¥æ–‡ä»¶ä¸­æ²¡æœ‰å¥å­åˆ‡åˆ†ç»“æœ")
            print("è¯·ç¡®è®¤é¢„å¤„ç†æ—¶å¯ç”¨äº†å¥å­åˆ‡åˆ†åŠŸèƒ½ (split_sentences=True)")
            return
        
        # æå–å¥å­
        print("æ­£åœ¨æå–å¥å­...")
        sentences_df = analyzer.extract_sentences()
        
        if len(sentences_df) == 0:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å¥å­åˆ‡åˆ†ç»“æœ")
            return
        
        # åˆ†æå¥å­
        print("æ­£åœ¨åˆ†æå¥å­ç»Ÿè®¡ä¿¡æ¯...")
        analysis = analyzer.analyze_sentences(sentences_df)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        for output_path in [output_sentences, output_summary, output_samples]:
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        # å¯¼å‡ºç»“æœ
        print("æ­£åœ¨å¯¼å‡ºç»“æœ...")
        analyzer.export_sentences(output_sentences, sentences_df)
        analyzer.export_summary(output_summary, analysis)
        
        # ç”Ÿæˆæ ·æœ¬
        sample_df = analyzer.generate_sample_sentences(sentences_df, sample_size)
        if len(sample_df) > 0:
            sample_df.to_csv(output_samples, index=False, encoding='utf-8-sig')
            print(f"å¥å­æ ·æœ¬å·²å¯¼å‡ºåˆ°: {output_samples}")
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        print("\n" + "="*50)
        print("âœ… å¥å­åˆ‡åˆ†åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"   - æ€»å¥å­æ•°: {analysis['total_sentences']:,}")
        print(f"   - åŸå§‹æ–‡æœ¬æ•°: {analysis['total_original_texts']:,}")
        print(f"   - å¹³å‡æ¯æ¡æ–‡æœ¬å¥æ•°: {analysis['avg_sentences_per_text']:.2f}")
        
        print(f"ğŸ“ å¥å­é•¿åº¦ç»Ÿè®¡:")
        length_stats = analysis['sentence_length_stats']
        print(f"   - å¹³å‡é•¿åº¦: {length_stats['mean']:.1f} å­—ç¬¦")
        print(f"   - ä¸­ä½æ•°é•¿åº¦: {length_stats['median']:.1f} å­—ç¬¦")
        print(f"   - é•¿åº¦èŒƒå›´: {length_stats['min']} - {length_stats['max']} å­—ç¬¦")
        
        print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶:")
        print(f"   - å¥å­è¡¨: {output_sentences}")
        print(f"   - åˆ†ææŠ¥å‘Š: {output_summary}")
        print(f"   - å¥å­æ ·æœ¬: {output_samples}")
        
        # è¯­è¨€åˆ†å¸ƒ
        if 'language_distribution' in analysis and analysis['language_distribution']:
            print(f"ğŸŒ è¯­è¨€åˆ†å¸ƒ:")
            for lang, count in analysis['language_distribution'].items():
                percentage = (count / analysis['total_sentences']) * 100
                print(f"   - {lang}: {count:,} å¥å­ ({percentage:.1f}%)")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        logging.error(f"åˆ†æå¼‚å¸¸: {e}", exc_info=True)

if __name__ == "__main__":
    main()


# ========== ä½¿ç”¨è¯´æ˜ ==========
"""
ğŸ”§ ä½¿ç”¨æ­¥éª¤ï¼š

1. ğŸ“‹ ç¡®ä¿å·²è¿è¡Œé¢„å¤„ç†è„šæœ¬ä¸”å¯ç”¨äº†å¥å­åˆ‡åˆ†åŠŸèƒ½
2. âœï¸  ä¿®æ”¹ä¸Šé¢çš„è¾“å…¥æ–‡ä»¶è·¯å¾„
3. ğŸš€ è¿è¡Œ: python run_sentence_analysis.py
4. ğŸ“Š æŸ¥çœ‹ç”Ÿæˆçš„åˆ†æç»“æœ

ğŸ“„ è¾“å‡ºæ–‡ä»¶è¯´æ˜ï¼š
- sentences.csv: åŒ…å«æ‰€æœ‰åˆ‡åˆ†åçš„å¥å­ï¼Œæ¯è¡Œä¸€ä¸ªå¥å­
- sentence_report.md: è¯¦ç»†çš„åˆ†ææŠ¥å‘Š
- sentence_samples.csv: æŒ‰é•¿åº¦åˆ†å±‚é‡‡æ ·çš„å¥å­æ ·æœ¬

ğŸ“Š å¥å­è¡¨åŒ…å«çš„åˆ—ï¼š
- original_id: åŸå§‹æ–‡æœ¬ID
- sentence_index: å¥å­åœ¨åŸæ–‡ä¸­çš„ç´¢å¼•
- sentence_text: å¥å­å†…å®¹
- sentence_start/end: å¥å­åœ¨åŸæ–‡ä¸­çš„ä½ç½®
- sentence_lang: å¥å­è¯­è¨€
- original_text: åŸå§‹æ–‡æœ¬
- cleaned_text: æ¸…æ´—åæ–‡æœ¬
- sentence_length: å¥å­é•¿åº¦
""" 