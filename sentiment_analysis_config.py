#!/usr/bin/env python3
"""
æ±½è½¦å·¥å•æƒ…æ„Ÿåˆ†æä¸“ç”¨é…ç½®
é’ˆå¯¹æ±½è½¦ç»´ä¿®æœåŠ¡åœºæ™¯ä¼˜åŒ–çš„æƒ…æ„Ÿåˆ†æé…ç½®
"""

import asyncio
from batch_llm_api import APIConfig, ProcessConfig, LLMBatchProcessor

async def car_service_sentiment_analysis():
    """æ±½è½¦æœåŠ¡å·¥å•æƒ…æ„Ÿåˆ†æ"""
    
    # APIé…ç½® - ä¸“é—¨é’ˆå¯¹æ±½è½¦æœåŠ¡åœºæ™¯
    api_config = APIConfig(
        api_key="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",
        model="google/gemini-2.5-flash-preview-05-20",
        max_concurrent=3,
        timeout=60,
        retry_attempts=2,
        system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ±½è½¦æœåŠ¡è¡Œä¸šæƒ…æ„Ÿåˆ†æä¸“å®¶ï¼Œä¸“é—¨åˆ†ææ±½è½¦ç»´ä¿®ã€ä¿å…»ã€é”€å”®ç­‰æœåŠ¡åœºæ™¯ä¸­çš„å®¢æˆ·åé¦ˆã€‚

ä¸“ä¸šèƒŒæ™¯ï¼š
- æ·±åº¦äº†è§£æ±½è½¦è¡Œä¸šæœ¯è¯­å’ŒæœåŠ¡æµç¨‹
- ç†Ÿæ‚‰å®¢æˆ·åœ¨æ±½è½¦æœåŠ¡ä¸­çš„å¸¸è§å…³æ³¨ç‚¹
- èƒ½å¤Ÿå‡†ç¡®è¯†åˆ«æœåŠ¡è´¨é‡ã€æŠ€æœ¯æ°´å¹³ã€ä»·æ ¼åˆç†æ€§ç­‰æ–¹é¢çš„æƒ…æ„Ÿ

åˆ†æè¦æ±‚ï¼š
1. æƒ…æ„Ÿåˆ†ç±»ï¼špositive(æ­£é¢)/negative(è´Ÿé¢)/neutral(ä¸­æ€§)
2. ç½®ä¿¡åº¦ï¼š0.0-1.0ï¼Œåæ˜ åˆ†æçš„ç¡®å®šæ€§
3. å…·ä½“æƒ…ç»ªï¼šå¦‚æ»¡æ„ã€ä¸æ»¡ã€æ‹…å¿§ã€èµèµã€æŠ±æ€¨ç­‰
4. å…³é”®è¯ï¼šæå–åæ˜ æƒ…æ„Ÿçš„å…³é”®è¯æ±‡
5. è¯„åˆ†ï¼š1-5åˆ†åˆ¶ï¼ˆ1=å¾ˆä¸æ»¡æ„ï¼Œ2=ä¸æ»¡æ„ï¼Œ3=ä¸€èˆ¬ï¼Œ4=æ»¡æ„ï¼Œ5=å¾ˆæ»¡æ„ï¼‰
6. æœåŠ¡ç»´åº¦ï¼šè¯†åˆ«æ¶‰åŠçš„æœåŠ¡æ–¹é¢ï¼ˆå¦‚æŠ€æœ¯ã€æ€åº¦ã€ä»·æ ¼ã€æ—¶æ•ˆç­‰ï¼‰

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›
- æ‰€æœ‰å­—æ®µéƒ½è¦å¡«å†™ï¼Œå¦‚æœæ— æ³•ç¡®å®šåˆ™æ ‡æ³¨ä¸ºnull
- å…³é”®è¯è¦å…·ä½“ä¸”ç›¸å…³"""
    )
    
    # å¤„ç†é…ç½®
    process_config = ProcessConfig(
        input_csv="N7åŸå§‹æ•°æ®.csv",
        output_csv="æ±½è½¦æœåŠ¡æƒ…æ„Ÿåˆ†æç»“æœ.csv",
        input_column="å†…å®¹",
        prompt_template="""è¯·åˆ†æä»¥ä¸‹æ±½è½¦æœåŠ¡ç›¸å…³æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼š

å®¢æˆ·åé¦ˆå†…å®¹ï¼š{input_text}

è¯·ä»æ±½è½¦æœåŠ¡è¡Œä¸šçš„è§’åº¦è¿›è¡Œä¸“ä¸šåˆ†æï¼Œè¿”å›ä»¥ä¸‹JSONæ ¼å¼ï¼š

{{
    "sentiment": "positive/negative/neutral",
    "confidence": 0.85,
    "emotion": "å…·ä½“æƒ…ç»ªæè¿°ï¼ˆå¦‚ï¼šæ»¡æ„ã€ä¸æ»¡ã€æ‹…å¿§ç­‰ï¼‰",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"],
    "score": 4,
    "service_dimension": ["æŠ€æœ¯è´¨é‡", "æœåŠ¡æ€åº¦", "ä»·æ ¼", "æ—¶æ•ˆæ€§"],
    "main_concern": "å®¢æˆ·ä¸»è¦å…³æ³¨çš„é—®é¢˜",
    "suggestion": "æ”¹è¿›å»ºè®®ï¼ˆå¦‚æœæ˜¯è´Ÿé¢åé¦ˆï¼‰"
}}""",
        
        output_json_fields=[
            "sentiment", "confidence", "emotion", "keywords", 
            "score", "service_dimension", "main_concern", "suggestion"
        ],
        
        max_rows=50  # æµ‹è¯•ç”¨ï¼Œå¯ä»¥è°ƒæ•´ä¸ºNoneå¤„ç†å…¨éƒ¨æ•°æ®
    )
    
    print("ğŸš— æ±½è½¦æœåŠ¡æƒ…æ„Ÿåˆ†æå¼€å§‹...")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {process_config.input_csv}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {process_config.output_csv}")
    print(f"ğŸ¯ åˆ†æç»´åº¦: æƒ…æ„Ÿã€ç½®ä¿¡åº¦ã€å…·ä½“æƒ…ç»ªã€å…³é”®è¯ã€è¯„åˆ†ã€æœåŠ¡ç»´åº¦")
    print("-" * 60)
    
    try:
        async with LLMBatchProcessor(api_config, process_config) as processor:
            result_df = await processor.process_batch()
            processor.save_results(result_df)
            
            # è¯¦ç»†ç»Ÿè®¡åˆ†æ
            total_rows = len(result_df)
            success_rows = len(result_df[result_df['parsing_success'] == True])
            success_rate = success_rows / total_rows * 100 if total_rows > 0 else 0
            
            print("-" * 60)
            print("âœ… æ±½è½¦æœåŠ¡æƒ…æ„Ÿåˆ†æå®Œæˆï¼")
            print(f"ğŸ“Š æ€»å¤„ç†è¡Œæ•°: {total_rows}")
            print(f"âœ… æˆåŠŸå¤„ç†: {success_rows}")
            print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
            
            # æƒ…æ„Ÿåˆ†å¸ƒç»Ÿè®¡
            if success_rows > 0:
                sentiment_counts = result_df['sentiment'].value_counts()
                print("\nğŸ“Š æƒ…æ„Ÿåˆ†å¸ƒ:")
                for sentiment, count in sentiment_counts.items():
                    percentage = count / success_rows * 100
                    print(f"  {sentiment}: {count}æ¡ ({percentage:.1f}%)")
                
                # å¹³å‡è¯„åˆ†
                avg_score = result_df['score'].dropna().mean()
                if not pd.isna(avg_score):
                    print(f"\nâ­ å¹³å‡æ»¡æ„åº¦è¯„åˆ†: {avg_score:.2f}/5.0")
                
                print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {process_config.output_csv}")
                
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import pandas as pd
    
    print("ğŸš— æ±½è½¦æœåŠ¡æƒ…æ„Ÿåˆ†æä¸“ç”¨å·¥å…·")
    print("=" * 60)
    print("ä¸“é—¨é’ˆå¯¹æ±½è½¦ç»´ä¿®ã€ä¿å…»ã€é”€å”®ç­‰æœåŠ¡åœºæ™¯çš„æƒ…æ„Ÿåˆ†æ")
    print("åˆ†æç»´åº¦ï¼šæƒ…æ„Ÿå€¾å‘ã€ç½®ä¿¡åº¦ã€å…·ä½“æƒ…ç»ªã€å…³é”®è¯ã€è¯„åˆ†ã€æœåŠ¡ç»´åº¦")
    print()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    import os
    if not os.path.exists("N7åŸå§‹æ•°æ®.csv"):
        print("âŒ æ‰¾ä¸åˆ°N7åŸå§‹æ•°æ®.csvæ–‡ä»¶")
        print("è¯·ç¡®ä¿æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹")
        exit(1)
    
    # é¢„è§ˆæ•°æ®
    try:
        df = pd.read_csv("N7åŸå§‹æ•°æ®.csv")
        print(f"ğŸ“‹ æ•°æ®é¢„è§ˆ: å…±{len(df)}è¡Œæ•°æ®")
        if 'å†…å®¹' in df.columns:
            print("âœ… æ‰¾åˆ°'å†…å®¹'åˆ—")
            print("å‰3æ¡æ•°æ®å†…å®¹:")
            for i, content in enumerate(df['å†…å®¹'].head(3)):
                print(f"  {i+1}. {str(content)[:50]}...")
        else:
            print("âŒ æ‰¾ä¸åˆ°'å†…å®¹'åˆ—ï¼Œè¯·æ£€æŸ¥CSVæ–‡ä»¶æ ¼å¼")
            print(f"å½“å‰åˆ—å: {list(df.columns)}")
            exit(1)
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        exit(1)
    
    print("\n" + "="*60)
    input("æŒ‰å›è½¦é”®å¼€å§‹åˆ†æ...")
    
    # è¿è¡Œåˆ†æ
    asyncio.run(car_service_sentiment_analysis()) 