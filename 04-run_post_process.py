#!/usr/bin/env python3
"""
ç¬¬4æ­¥ï¼šåå¤„ç†åˆ†æè„šæœ¬
ä¸»è¦åŠŸèƒ½ï¼š
1. éªŒè¯tagåˆ—æ˜¯å¦å­˜åœ¨äºå·²æœ‰æ ‡ç­¾ä½“ç³»ä¸­
2. åˆ¤æ–­brandå’Œmodelæ˜¯å¦å±äºå…³å¿ƒçš„è½¦å‹
"""

import pandas as pd
import os
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def get_predefined_tags():
    """è·å–é¢„å®šä¹‰çš„æ ‡ç­¾ä½“ç³»"""
    predefined_tags = [
        "äº§å“æ”¯æŒ#äº§å“ä½“éªŒ#äº§å“å»ºè®®#äº§å“å»ºè®®",
"äº§å“æ”¯æŒ#äº§å“ä½“éªŒ#äº§å“ç»­èˆª#äº§å“ç»­èˆª",
"äº§å“æ”¯æŒ#äº§å“ä½“éªŒ#äº§å“è®¾è®¡#äº§å“è®¾è®¡",
"äº§å“æ”¯æŒ#äº§å“ä½“éªŒ#éª‘è¡Œä½“éªŒ#éª‘è¡Œä½“éªŒ",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#ç”µæ± ç±»#æ‰ç”µå¿«",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#å¼‚å“ç±»#åˆ¹è½¦å¼‚å“",
"äº§å“æ”¯æŒ#äº§å“ä½“éªŒ#äº§å“æ€§èƒ½#é€Ÿåº¦",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#å¤–è§‚ç±»#å¤–è§‚ä¸è‰¯",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#å……ç”µç±»#æ— æ³•å……ç”µ",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#æ˜¾ç¤ºç±»#æ˜¾ç¤ºå±æ˜¾ç¤ºå¼‚å¸¸",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#å¤–è§‚ç±»#å¤–è§‚ä»¶æ–­è£‚/è„±è½",
"äº§å“æ”¯æŒ#APP#è®¾å¤‡é¦–é¡µ#è“ç‰™è¿æ¥",
"äº§å“æ”¯æŒ#APP#è®¾å¤‡æ•°æ®#éª‘è¡Œè½¨è¿¹",
"äº§å“æ”¯æŒ#äº§å“ä½“éªŒ#äº§å“æ€§èƒ½#åˆ¹è½¦",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#éª‘è¡Œç±»#éª‘è¡Œæ–­ç”µ",
"äº§å“æ”¯æŒ#äº§å“å’¨è¯¢#äº§å“ä½¿ç”¨#äº§å“ä½¿ç”¨",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#ç¯ç±»#ç¯å…‰å¼‚å¸¸",
"äº§å“æ”¯æŒ#äº§å“ä½“éªŒ#äº§å“æ€§èƒ½#å‡éœ‡",
"äº§å“æ”¯æŒ#APP#æ™ºèƒ½é˜²ç›—#æ™ºèƒ½æœåŠ¡è´¹",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#éª‘è¡Œç±»#éª‘è¡Œæ™ƒåŠ¨/æŠ–åŠ¨",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#å¼‚å“ç±»#å‰/åè½®å¼‚å“",
"äº§å“æ”¯æŒ#äº§å“å’¨è¯¢#äº§å“æ”¹è£…#äº§å“æ”¹è£…",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#å¼‚å“ç±»#å‡éœ‡å¼‚å“",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#å¼€å…³æœºç±»#æ— æ³•å¼€å…³æœº",
"äº§å“æ”¯æŒ#APP#è®¾å¤‡æ•°æ®#å‰©ä½™é‡Œç¨‹ï¼ˆç»­èˆªï¼‰",
"äº§å“æ”¯æŒ#APP#åŠŸèƒ½è®¾ç½®#æ°®æ°”åŠ é€Ÿå¼€å…³",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#æ²¹é—¨/åˆ¹è½¦ç±»#æ²¹é—¨/åˆ¹è½¦å¤±çµ",
"äº§å“æ”¯æŒ#äº§å“ä½“éªŒ#äº§å“æ€§èƒ½#åŠ é€Ÿ",
"äº§å“æ”¯æŒ#äº§å“ä½“éªŒ#äº§å“æ€§èƒ½#çˆ¬å¡",
"äº§å“æ”¯æŒ#APP#è®¾å¤‡æ•°æ®#ç²¾å‡†ç»­èˆª",
"äº§å“æ”¯æŒ#APP#åŠŸèƒ½è®¾ç½®#æ²¹é—¨è½¬æŠŠ",
"äº§å“æ”¯æŒ#APP#æ™ºèƒ½é˜²ç›—#å¼‚åŠ¨æŠ¥è­¦",
"äº§å“æ”¯æŒ#APP#åŠŸèƒ½è®¾ç½®#èƒ½é‡å›æ”¶",
"äº§å“æ”¯æŒ#äº§å“æ•…éšœ#å¼€å…³æœºç±»#è‡ªåŠ¨å¼€å…³æœº",
"æœåŠ¡#æ”¿ç­–æ³•è§„#åœ°æ–¹æ”¿ç­–#ä¸Šç‰Œ/ä¸Šè·¯/æºå¸¦/ç¦æ‘©/é™æ‘©",
"æœåŠ¡#æ”¿ç­–æ³•è§„#ä¸‰åŒ…æ”¿ç­–#ä¿ä¿®æ ‡å‡†",
"æœåŠ¡#çº¿ä¸‹æœåŠ¡#æœåŠ¡åº—äººå‘˜æŠ•è¯‰#æœåŠ¡æ€åº¦",
"é”€å”®#çº¿ä¸Šé”€å”®#çº¿ä¸Šé”€å”®é¡µé¢#çº¿ä¸Šé”€å”®é¡µé¢",
"é”€å”®#çº¿ä¸‹é”€å”®#é”€å”®é—¨åº—#é—¨åº—ä»·æ ¼",
"é”€å”®#çº¿ä¸‹é”€å”®#é”€å”®é—¨åº—#éæ–°å“/éå®˜æ–¹",
"é”€å”®#çº¿ä¸Šé”€å”®#çº¿ä¸Šé”€å”®è®¢å•#çº¿ä¸Šé”€å”®è®¢å•",
"é”€å”®#çº¿ä¸Šé”€å”®#çº¿ä¸Šé”€å”®è®¢å•#é™ä»·",
"é”€å”®#çº¿ä¸‹é”€å”®#é”€å”®é—¨åº—#é—¨åº—ä¸Šç‰Œ",
"é”€å”®#çº¿ä¸‹é”€å”®#é”€å”®é—¨åº—#é”€å”®åº—äººå‘˜æŠ•è¯‰",
"é”€å”®#çº¿ä¸‹é”€å”®#é”€å”®é—¨åº—#æ ¸é”€/äº¤ä»˜",
"é”€å”®#çº¿ä¸Šé”€å”®#çº¿ä¸Šé”€å”®é€€æ¬¾#çº¿ä¸Šé”€å”®é€€æ¬¾",
"ç–‘ä¼¼å±æœº#ç–‘ä¼¼å±æœº#åª’ä½“/å¹³å°#å¾®åš/é»‘çŒ«/æŠ–éŸ³/å°çº¢ä¹¦/ç¤¾ç¾¤/è´´å§/æ¶ˆè´¹ä¿",
"ç–‘ä¼¼å±æœº#ç–‘ä¼¼å±æœº#æ‘”è½¦å®¢è¯‰#è½»å¾®æ“¦ä¼¤æˆ–ç ´çš®",
"ç–‘ä¼¼å±æœº#ç–‘ä¼¼å±æœº#æ‘”è½¦å®¢è¯‰#å››è‚¢éª¨æŠ˜ç­‰å¯¹äºäººèº«å¥åº·æœ‰é‡å¤§çš„æŸå",
"è¥é”€#è¥é”€æ´»åŠ¨#æ–°å“å‘å¸ƒ#æ–°å“å‘å¸ƒ",
    ]
    return set(predefined_tags)

def get_target_brands_models():
    """è·å–å…³å¿ƒçš„å“ç‰Œå’Œè½¦å‹ä¿¡æ¯ï¼ŒåŒ…å«è½¦å‹åˆ«å"""
    target_info = {
        # Segwayæœ¬å“
        "Segway": {
            "ZT3 Pro": ["ZT3 Pro", "ZT3Pro", "zt3 pro", "zt3pro", "ZT3", "zt3", "ZT3P", "zt3p"],
            "Max G2": ["Max G2", "MaxG2", "max g2", "maxg2", "MAX G2", "MAXG2", "G2", "g2"]
        },
        "segway": {
            "ZT3 Pro": ["ZT3 Pro", "ZT3Pro", "zt3 pro", "zt3pro", "ZT3", "zt3", "ZT3P", "zt3p"],
            "Max G2": ["Max G2", "MaxG2", "max g2", "maxg2", "MAX G2", "MAXG2", "G2", "g2"]
        },
        
        # ç«å“Navee
        "Navee": {
            "S65C": ["S65C", "s65c", "S65", "s65", "65C", "65c"]
        },
        "navee": {
            "S65C": ["S65C", "s65c", "S65", "s65", "65C", "65c"]
        },
        
        # ç«å“å°ç±³
        "å°ç±³": {
            "4 Pro Max": ["4 Pro Max", "4ProMax", "4 pro max", "4promax", "4PM", "4pm", "Pro Max", "pro max"]
        },
        "xiaomi": {
            "4 Pro Max": ["4 Pro Max", "4ProMax", "4 pro max", "4promax", "4PM", "4pm", "Pro Max", "pro max"]
        },
        
        # ç«å“Kaabo
        "Kaabo": {
            "Mantis 10": ["Mantis 10", "Mantis10", "mantis 10", "mantis10", "Mantis", "mantis", "M10", "m10"]
        },
        "kaabo": {
            "Mantis 10": ["Mantis 10", "Mantis10", "mantis 10", "mantis10", "Mantis", "mantis", "M10", "m10"]
        },
        
        # ç«å“Dualtron
        "Dualtron": {
            "Mini": ["Mini", "mini", "MINI", "Dualtron Mini", "dualtron mini"]
        },
        "dualtron": {
            "Mini": ["Mini", "mini", "MINI", "Dualtron Mini", "dualtron mini"]
        }
    }
    return target_info

def check_tag_in_predefined(tag, predefined_tags):
    """æ£€æŸ¥tagæ˜¯å¦åœ¨é¢„å®šä¹‰æ ‡ç­¾ä½“ç³»ä¸­"""
    if pd.isna(tag) or tag == "":
        return False
    return str(tag).strip() in predefined_tags

def normalize_brand_model(brand, model, target_info):
    """è§„èŒƒåŒ–å“ç‰Œå’Œè½¦å‹åç§°"""
    if pd.isna(brand) or brand == "":
        return "å…¶ä»–", "å…¶ä»–"
    
    brand_str = str(brand).strip().lower()
    model_str = str(model).strip().lower() if not pd.isna(model) else ""
    
    # å“ç‰Œæ˜ å°„è¡¨
    brand_mapping = {
        "Segway": "Segway",
        "segway": "Segway",
        "ä¹å·": "Segway",
        "ä¹å·ç”µåŠ¨è½¦": "Segway",
        "ninebot": "Segway",
        "Navee": "Navee",
        "navee": "Navee",
        "å°ç±³": "å°ç±³",
        "xiaomi": "å°ç±³",
        "Kaabo": "Kaabo",
        "kaabo": "Kaabo",
        "Dualtron": "Dualtron",
        "dualtron": "Dualtron"
    }
    
    # æ£€æŸ¥å“ç‰ŒåŒ¹é…å¹¶è§„èŒƒåŒ–
    normalized_brand = "å…¶ä»–"
    matched_model_dict = {}
    
    for target_brand, model_dict in target_info.items():
        if target_brand.lower() in brand_str or brand_str in target_brand.lower():
            normalized_brand = brand_mapping.get(target_brand, "å…¶ä»–")
            matched_model_dict = model_dict
            break
    
    # æ£€æŸ¥è½¦å‹åŒ¹é…å¹¶è§„èŒƒåŒ–
    normalized_model = "å…¶ä»–"
    if normalized_brand != "å…¶ä»–" and model_str:
        for standard_model, aliases in matched_model_dict.items():
            for alias in aliases:
                # æ£€æŸ¥å®Œå…¨åŒ¹é…æˆ–åŒ…å«å…³ç³»
                if (alias.lower() == model_str or 
                    alias.lower() in model_str or 
                    model_str in alias.lower()):
                    normalized_model = standard_model
                    break
            if normalized_model != "å…¶ä»–":
                break
    
    return normalized_brand, normalized_model

def process_data(input_file, output_file):
    """å¤„ç†æ•°æ®ï¼Œæ·»åŠ éªŒè¯åˆ—"""
    print(f"ğŸ”„ å¼€å§‹å¤„ç†æ–‡ä»¶: {input_file}")
    
    # è¯»å–æ•°æ®
    df = pd.read_csv(input_file)
    print(f"ğŸ“Š è¯»å–æ•°æ®è¡Œæ•°: {len(df)}")
    
    # è·å–é¢„å®šä¹‰æ ‡ç­¾å’Œç›®æ ‡å“ç‰Œè½¦å‹
    predefined_tags = get_predefined_tags()
    target_info = get_target_brands_models()
    
    print(f"ğŸ“‹ é¢„å®šä¹‰æ ‡ç­¾æ•°é‡: {len(predefined_tags)}")
    print(f"ğŸ¯ ç›®æ ‡å“ç‰Œæ•°é‡: {len(target_info)}")
    
    # 1. æ£€æŸ¥tagæ˜¯å¦åœ¨é¢„å®šä¹‰æ ‡ç­¾ä½“ç³»ä¸­
    print("ğŸ·ï¸  æ£€æŸ¥æ ‡ç­¾æ˜¯å¦åœ¨é¢„å®šä¹‰ä½“ç³»ä¸­...")
    df['is_tag_in_predefined'] = df['tag'].apply(
        lambda x: check_tag_in_predefined(x, predefined_tags)
    )
    
    # 2. è§„èŒƒåŒ–å“ç‰Œå’Œè½¦å‹åç§°
    print("ğŸš— è§„èŒƒåŒ–å“ç‰Œå’Œè½¦å‹åç§°...")
    brand_model_results = df.apply(
        lambda row: normalize_brand_model(row['brand'], row['model'], target_info),
        axis=1
    )
    
    df['normalized_brand'] = [result[0] for result in brand_model_results]
    df['normalized_model'] = [result[1] for result in brand_model_results]
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_rows = len(df)  # åŸå§‹æ•°é‡ï¼ˆåŒ…å«æ‰€æœ‰æ•°æ®ï¼‰
    valid_sentences = len(df[df['is_valid'] == 1])  # æœ‰æ•ˆå¥å­æ•°é‡
    invalid_sentences = len(df[df['is_valid'] == 0])  # æ— æ•ˆå¥å­æ•°é‡
    
    # åªåœ¨æœ‰æ•ˆå¥å­ä¸­ç»Ÿè®¡æ ‡ç­¾å’Œå“ç‰Œè½¦å‹
    valid_df = df[df['is_valid'] == 1]
    valid_tags = valid_df['is_tag_in_predefined'].sum() if len(valid_df) > 0 else 0
    target_brands = len(valid_df[valid_df['normalized_brand'] != 'å…¶ä»–']) if len(valid_df) > 0 else 0
    target_models = len(valid_df[valid_df['normalized_model'] != 'å…¶ä»–']) if len(valid_df) > 0 else 0
    
    print("\nğŸ“ˆ ç»Ÿè®¡ç»“æœ:")
    print(f"  åŸå§‹æ•°æ®æ€»æ•°: {total_rows}")
    print(f"  æœ‰æ•ˆå¥å­æ•°é‡: {valid_sentences} ({valid_sentences/total_rows*100:.1f}%)")
    print(f"  æ— æ•ˆå¥å­æ•°é‡: {invalid_sentences} ({invalid_sentences/total_rows*100:.1f}%)")
    print()
    print(f"  æœ‰æ•ˆå¥å­ä¸­çš„ç»Ÿè®¡:")
    if valid_sentences > 0:
        print(f"    æœ‰æ•ˆæ ‡ç­¾æ•°: {valid_tags} ({valid_tags/valid_sentences*100:.1f}%)")
        print(f"    ç›®æ ‡å“ç‰Œæ•°: {target_brands} ({target_brands/valid_sentences*100:.1f}%)")
        print(f"    ç›®æ ‡è½¦å‹æ•°: {target_models} ({target_models/valid_sentences*100:.1f}%)")
    else:
        print(f"    æ— æœ‰æ•ˆå¥å­è¿›è¡Œåˆ†æ")
    
    # å“ç‰Œåˆ†å¸ƒç»Ÿè®¡ï¼ˆä»…ç»Ÿè®¡æœ‰æ•ˆå¥å­ï¼‰
    if valid_sentences > 0:
        brand_counts = valid_df['normalized_brand'].value_counts()
        print(f"\nğŸ“Š æœ‰æ•ˆå¥å­ä¸­çš„å“ç‰Œåˆ†å¸ƒ:")
        for brand, count in brand_counts.items():
            print(f"  {brand}: {count} ({count/valid_sentences*100:.1f}%)")
        
        # è½¦å‹åˆ†å¸ƒç»Ÿè®¡ï¼ˆä»…æ˜¾ç¤ºé'å…¶ä»–'çš„è½¦å‹ï¼‰
        model_counts = valid_df[valid_df['normalized_model'] != 'å…¶ä»–']['normalized_model'].value_counts()
        if len(model_counts) > 0:
            print(f"\nğŸš— æœ‰æ•ˆå¥å­ä¸­çš„è½¦å‹åˆ†å¸ƒ:")
            for model, count in model_counts.items():
                print(f"  {model}: {count} ({count/valid_sentences*100:.1f}%)")
        else:
            print(f"\nğŸš— æœ‰æ•ˆå¥å­ä¸­æ— ç›®æ ‡è½¦å‹æ•°æ®")
    else:
        print(f"\nğŸ“Š æ— æœ‰æ•ˆå¥å­è¿›è¡Œå“ç‰Œè½¦å‹åˆ†å¸ƒç»Ÿè®¡")
    
    # ä¿å­˜ç»“æœ
    print(f"\nğŸ’¾ ä¿å­˜ç»“æœåˆ°: {output_file}")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    df.to_csv(output_file, index=False)
    
    print("âœ… å¤„ç†å®Œæˆï¼")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹ç»“æœï¼ˆä»…é’ˆå¯¹æœ‰æ•ˆå¥å­ï¼‰
    print("\nğŸ“‹ ç»“æœé¢„è§ˆ:")
    
    if valid_sentences > 0:
        # æ˜¾ç¤ºæœ‰æ•ˆæ ‡ç­¾çš„ä¾‹å­
        valid_tag_examples = valid_df[valid_df['is_tag_in_predefined'] == True]['tag'].dropna().head(3).tolist()
        if valid_tag_examples:
            print(f"  æœ‰æ•ˆæ ‡ç­¾ç¤ºä¾‹: {valid_tag_examples}")
        
        # æ˜¾ç¤ºè§„èŒƒåŒ–å“ç‰Œè½¦å‹çš„ä¾‹å­
        target_examples = valid_df[valid_df['normalized_brand'] != 'å…¶ä»–'][['brand', 'model', 'normalized_brand', 'normalized_model']].dropna().head(3)
        if len(target_examples) > 0:
            print("  å“ç‰Œè½¦å‹è§„èŒƒåŒ–ç¤ºä¾‹:")
            for idx, row in target_examples.iterrows():
                print(f"    åŸå§‹: {row['brand']}/{row['model']} -> è§„èŒƒåŒ–: {row['normalized_brand']}/{row['normalized_model']}")
        
        # æ˜¾ç¤ºæ— æ•ˆæ ‡ç­¾çš„ä¾‹å­
        invalid_tag_examples = valid_df[valid_df['is_tag_in_predefined'] == False]['tag'].dropna().head(3).tolist()
        if invalid_tag_examples:
            print(f"  æ— æ•ˆæ ‡ç­¾ç¤ºä¾‹: {invalid_tag_examples}")
    else:
        print("  æ— æœ‰æ•ˆå¥å­å¯ä¾›é¢„è§ˆ")
    
    return df

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ç¬¬4æ­¥ï¼šåå¤„ç†åˆ†æ")
    print("=" * 50)
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    input_file = "data/results/å¢ƒå¤–æ±‡æ€»_20250609-cleaned-sentences-results.csv"
    output_file = "data/results/å¢ƒå¤–æ±‡æ€»_20250609_cleaned-sentences-results-processed.csv"
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        print("ğŸ’¡ è¯·ç¡®ä¿ç¬¬3æ­¥çš„åˆ†æå·²ç»å®Œæˆå¹¶ç”Ÿæˆäº†ç»“æœæ–‡ä»¶")
        return
    
    try:
        # å¤„ç†æ•°æ®
        df = process_data(input_file, output_file)
        
        print(f"\nğŸ‰ æ‰€æœ‰å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_file}")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"ğŸ“Š æ–°å¢åˆ—:")
        print(f"   - is_tag_in_predefined: æ ‡ç­¾æ˜¯å¦åœ¨é¢„å®šä¹‰ä½“ç³»ä¸­")
        print(f"   - normalized_brand: è§„èŒƒåŒ–å“ç‰Œåç§°ï¼ˆSegway/Navee/å°ç±³/Kaabo/Dualtron/å…¶ä»–ï¼‰")
        print(f"   - normalized_model: è§„èŒƒåŒ–è½¦å‹åç§°ï¼ˆZT3 Pro/Max G2/S65C/4 Pro Max/Mantis 10/Mini/å…¶ä»–ï¼‰")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥:")
        print("  1. è¾“å…¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
        print("  2. æ–‡ä»¶æ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨")
        print("  3. ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³")

if __name__ == "__main__":
    main() 